{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARND - Traffic Sign Classification Project\n",
    "==================================\n",
    "German traffic sign classification  as a part of the Self-driving Car Nanodegree program at Udacity using LeNet architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### Step 0: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "from src import loading, utils, lenet, preprocessing, augmentation\n",
    "from src.lenet import HYPER_PARAMETERS\n",
    "logger = utils.get_logger('Main Notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, test = loading.load_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Step 1: Dataset Summary & Exploration\n",
    "\n",
    "Task: provide a basic summary of the dataset, including an exploratory visualisation of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = utils.get_summary([training, validation, test])\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.hist(training.y, bins=summary['total-no-of-classes']);\n",
    "plt.title('Training labels distribution');\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.hist(validation.y, bins=summary['total-no-of-classes']);\n",
    "plt.title('Validation labels distribution');\n",
    "plt.tight_layout()\n",
    "plt.savefig('./docs/images/training-validation-histogram.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that training/validation is somehow balanced\n",
    "y_train_counts = utils.group_labels_by_counts(training)\n",
    "y_validation_counts = utils.group_labels_by_counts(validation)\n",
    "plt.plot(y_train_counts['counts']/ y_validation_counts['counts']);\n",
    "plt.title('Ratio of training to validation label distribution');\n",
    "plt.xlabel('Label');\n",
    "plt.ylabel('(training example count)/(validation example count)');\n",
    "plt.savefig('./docs/images/training-validation-sample-size-ratios.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "for i in range(50):\n",
    "    index = random.randint(0, training.count)\n",
    "    images.append(training.X[index])\n",
    "    labels.append(utils.to_sign_label(training.y[index]))\n",
    "utils.plot_and_save(images, labels, './docs/images/25-random-images.jpg', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_images = {\n",
    "    'with bad lighting': [17894, 14044],\n",
    "    'good': [22842, 4220]\n",
    "}\n",
    "images = []\n",
    "labels = []\n",
    "for label, indices in example_images.items():\n",
    "    for i in indices:\n",
    "        images.append(training.X[i])\n",
    "        labels.append(utils.to_sign_label(training.y[i]))\n",
    "\n",
    "utils.plot_and_save(images, labels, 'docs/images/cherry-pick-good-bad-images.jpg', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process and augment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of enabled data augmenters for training data set\n",
    "TRAINING_DATA_AUGMENTERS = [\n",
    "    augmentation.GaussianBlurAugmenter(),\n",
    "    augmentation.AffineTransformAugmenter(),\n",
    "    augmentation.AffineTransformAugmenter(),\n",
    "    augmentation.AffineTransformAugmenter(),\n",
    "    augmentation.AffineTransformAugmenter(),\n",
    "    augmentation.AffineTransformAugmenter(),\n",
    "]\n",
    "d_train = augmentation.Augmenter.apply(training, TRAINING_DATA_AUGMENTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of enabled data pre-processors\n",
    "PRE_PROCESSORS = [\n",
    "    preprocessing.GrayScaleConverter(),\n",
    "    preprocessing.ZNormaliser(),\n",
    "]\n",
    "\n",
    "# Perform pre-processing on augmented training and validation data sets\n",
    "d_train = preprocessing.PreProcessor.apply(d_train, PRE_PROCESSORS)\n",
    "d_validation = preprocessing.PreProcessor.apply(validation, PRE_PROCESSORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pre-processing to two of the \"bad\" images to show the results\n",
    "BAD_IMAGE_INDEX = [17894, 14044]\n",
    "\n",
    "bad_x = np.zeros((2, 32, 32, 3))\n",
    "bad_y = np.zeros(2,)\n",
    "for i in range(len(BAD_IMAGE_INDEX)):\n",
    "    bad_x[i,:] = training.X[BAD_IMAGE_INDEX[i]]\n",
    "    bad_y[i] = training.y[BAD_IMAGE_INDEX[i]]\n",
    "bad_examples = loading.DataSet('bad_samples', bad_x, bad_y, len(bad_x))\n",
    "\n",
    "pre_processed = preprocessing.PreProcessor.apply(bad_examples, PRE_PROCESSORS)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for i in range(len(BAD_IMAGE_INDEX)):\n",
    "    images.append(training.X[BAD_IMAGE_INDEX[i]]);\n",
    "    labels.append('Original')\n",
    "\n",
    "    images.append(pre_processed.X[i].squeeze());\n",
    "    labels.append('Pre-processed')\n",
    "utils.plot_and_save(images, labels, './docs/images/bad-images-pre-processed.jpg', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has been executed in the Udacity Workspace using GPU's to speed up training\n",
    "logger.info('Hyper-parameters: %s', HYPER_PARAMETERS)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "placeholders, operations = lenet.setup_graph()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    logger.info(\"Training...\")\n",
    "    for i in range(HYPER_PARAMETERS['EPOCHS']):\n",
    "        lenet.train_one_epoch(d_train, placeholders, operations)\n",
    "\n",
    "        training_accuracy = lenet.evaluate(d_train, placeholders, operations)\n",
    "        validation_accuracy = lenet.evaluate(d_validation, placeholders, operations)\n",
    "\n",
    "        logger.info(\"EPOCH {} ...\".format(i + 1))\n",
    "        logger.info(\"Accuracy on training dataset = {:.3f}\".format(training_accuracy))\n",
    "        logger.info(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        logger.info(\"\")\n",
    "\n",
    "    saver.save(sess, './data/model/lenet')\n",
    "    logger.info(\"Model saved\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "To give yourself more insight into how your model is working, download at least five pictures of German traffic signs from the web and use your model to predict the traffic sign type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Images Downloaded from the Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM_INTERNET_IMAGE_PATHS = [\n",
    "    \"max-50.jpeg\",\n",
    "    \"max-70.jpeg\",\n",
    "    \"priority-road.jpg\",\n",
    "    \"right-of-way-at-next-intersection.jpg\",\n",
    "    \"turn-right-ahead.jpg\"\n",
    "]\n",
    "FROM_INTERNET_LABELS = [2, 4, 12, 11, 33]\n",
    "from_internet_images = [utils.read_image_for_lenet('./data/traffic-signs-from-internet/' + p) for p in FROM_INTERNET_IMAGE_PATHS]\n",
    "\n",
    "plt_labels = ['{}: {}'.format(l, utils.to_sign_label(l)) for l in FROM_INTERNET_LABELS]\n",
    "utils.plot_and_save(from_internet_images, plt_labels, './docs/images/images-from-internet-resized.jpg', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "d_x = np.stack(from_internet_images)\n",
    "d_y = np.array(FROM_INTERNET_LABELS)\n",
    "\n",
    "from_internet_dataset = loading.DataSet('From Internet', d_x, d_y, len(d_x))\n",
    "logger.info(utils.get_summary([from_internet_dataset]))\n",
    "from_internet_dataset = preprocessing.PreProcessor.apply(from_internet_dataset, PRE_PROCESSORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Hyper-parameters: %s', HYPER_PARAMETERS)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "placeholders, operations = lenet.setup_graph()\n",
    "\n",
    "softmax_logits = tf.nn.softmax(operations.logits)\n",
    "all_labels = tf.nn.top_k(softmax_logits, k=43)\n",
    "top_5_labels = tf.nn.top_k(softmax_logits, k=5)\n",
    "\n",
    "saver2 = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver2.restore(sess, \"./data/model/lenet\")\n",
    "\n",
    "    accuracy = lenet.evaluate(from_internet_dataset, placeholders, operations)\n",
    "    logger.info(\"Accuracy = {:.3f}\".format(accuracy))\n",
    "    \n",
    "    top_5_results = sess.run(top_5_labels, feed_dict={\n",
    "        placeholders.x: from_internet_dataset.X,\n",
    "        placeholders.keep_probability: 1\n",
    "    })\n",
    "    all_labels_results = sess.run(all_labels, feed_dict={\n",
    "        placeholders.x: from_internet_dataset.X,\n",
    "        placeholders.keep_probability: 1\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(from_internet_dataset.count):\n",
    "    print('Actual: {}, {}'.format(FROM_INTERNET_LABELS[i], utils.to_sign_label(FROM_INTERNET_LABELS[i])))\n",
    "    for j in range(top_5_results.indices.shape[1]):\n",
    "        predicted_label = top_k_results.indices[i, j]\n",
    "        print(\"\\t[{}] {}: {}\".format(predicted_label, utils.to_sign_label(predicted_label), top_5_results.values[i, j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20, 15))\n",
    "for i in range(from_internet_dataset.count):\n",
    "    plt.subplot(from_internet_dataset.count, 1,i+1)\n",
    "    plt.bar(x=all_labels_results.indices[i], height=all_labels_results.values[i])\n",
    "    predicted_label = all_labels_results.indices[i][0]\n",
    "    actual_label = FROM_INTERNET_LABELS[i]\n",
    "    probability = all_labels_results.values[i][0]\n",
    "    plt.title(\"Predicted: {} ({}), Actual: {} ({}), Probability: {:.3f}\".format(predicted_label, \n",
    "                                                                               utils.to_sign_label(predicted_label),\n",
    "                                                                               actual_label, \n",
    "                                                                               utils.to_sign_label(actual_label),\n",
    "                                                                               probability))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"docs/images/softmax-probabilities-on-images-from-internet.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_80_LABEL = 5\n",
    "MAX_80_IMG_PATH = './data/traffic-signs-from-internet/max-80.jpg'\n",
    "max_80_img = utils.read_image_for_lenet(MAX_80_IMG_PATH)\n",
    "max_80_dataset = loading.DataSet('Max 80', max_80_img.reshape(1, 32, 32, 3), [MAX_80_LABEL], 1)\n",
    "d_max_80 = preprocessing.PreProcessor.apply(max_80_dataset, PRE_PROCESSORS)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "placeholders, operations = lenet.setup_graph()\n",
    "\n",
    "softmax_logits = tf.nn.softmax(operations.logits)\n",
    "all_labels = tf.nn.top_k(softmax_logits, k=43)\n",
    "\n",
    "saver3 = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver3.restore(sess, \"./data/model/lenet\")\n",
    "    all_labels_results = sess.run(all_labels, feed_dict={\n",
    "        placeholders.x: d_max_80.X,\n",
    "        placeholders.keep_probability: 1\n",
    "    })\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(max_80_img)\n",
    "plt.axis('off')\n",
    "a = plt.subplot(122)\n",
    "a.fi\n",
    "plt.bar(x=all_labels_results.indices[0], height=all_labels_results.values[0])\n",
    "predicted_label = all_labels_results.indices[0][0]\n",
    "probability = all_labels_results.values[0][0]\n",
    "plt.title(\"Predicted: {} ({}), Actual: {} ({}), Probability: {:.3f}\".format(predicted_label, \n",
    "                                                                           utils.to_sign_label(predicted_label),\n",
    "                                                                           MAX_80_LABEL, \n",
    "                                                                           utils.to_sign_label(MAX_80_LABEL),\n",
    "                                                                           probability));\n",
    "plt.savefig(\"docs/images/softmax-probabilities-on-max-80-sign.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize your network's feature maps here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# image_input: the test image being fed into the network to produce the feature maps\n",
    "# tf_activation: should be a tf variable name used during your training procedure that represents the calculated state of a specific weight layer\n",
    "# activation_min/max: can be used to view the activation contrast in more detail, by default matplot sets min and max to the actual min and max values of the output\n",
    "# plt_num: used to plot out multiple different weight feature map sets on the same block, just extend the plt number for each new feature map entry\n",
    "\n",
    "def outputFeatureMap(image_input, tf_activation, activation_min=-1, activation_max=-1 ,plt_num=1):\n",
    "    # Here make sure to preprocess your image_input in a way your network expects\n",
    "    # with size, normalization, ect if needed\n",
    "    # image_input =\n",
    "    # Note: x should be the same name as your network's tensorflow data placeholder variable\n",
    "    # If you get an error tf_activation is not defined it may be having trouble accessing the variable from inside a function\n",
    "    activation = tf_activation.eval(session=sess,feed_dict={x : image_input})\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(plt_num, figsize=(15,15))\n",
    "    for featuremap in range(featuremaps):\n",
    "        plt.subplot(6,8, featuremap+1) # sets the number of feature maps to show on each row and column\n",
    "        plt.title('FeatureMap ' + str(featuremap)) # displays the feature map number\n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin =activation_min, vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "placeholders, operations = lenet.setup_graph()\n",
    "\n",
    "d_test = preprocessing.PreProcessor.apply(test, PRE_PROCESSORS)\n",
    "\n",
    "saver3 = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver3.restore(sess, \"./data/model/lenet\")\n",
    "    accuracy = lenet.evaluate(d_test, placeholders, operations)\n",
    "    logger.info(\"Accuracy = {:.3f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
