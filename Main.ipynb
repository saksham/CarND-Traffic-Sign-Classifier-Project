{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARND - Traffic Sign Classification Project\n",
    "==================================\n",
    "German traffic sign classification  as a part of the Self-driving Car Nanodegree program at Udacity using LeNet architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### Step 0: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "from src import loading, utils, lenet, preprocessing, augmentation\n",
    "from src.lenet import HYPER_PARAMETERS, Mode\n",
    "logger = utils.get_logger('Main Notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, test = loading.load_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Step 1: Dataset Summary & Exploration\n",
    "\n",
    "Task: provide a basic summary of the dataset, including an exploratory visualisation of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = utils.get_summary([training, validation, test])\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.hist(training.y, bins=summary['total-no-of-classes']);\n",
    "plt.title('Training labels distribution');\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.hist(validation.y, bins=summary['total-no-of-classes']);\n",
    "plt.title('Validation labels distribution');\n",
    "plt.tight_layout()\n",
    "plt.savefig('./docs/images/training-validation-histogram.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that training/validation is somehow balanced\n",
    "y_train_counts = utils.group_labels_by_counts(training)\n",
    "y_validation_counts = utils.group_labels_by_counts(validation)\n",
    "plt.plot(y_train_counts['counts']/ y_validation_counts['counts']);\n",
    "plt.title('Ratio of training to validation label distribution');\n",
    "plt.xlabel('Label');\n",
    "plt.ylabel('(training example count)/(validation example count)');\n",
    "plt.savefig('./docs/images/training-validation-sample-size-ratios.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "for i in range(50):\n",
    "    index = random.randint(0, training.count)\n",
    "    images.append(training.X[index])\n",
    "    labels.append(utils.to_sign_label(training.y[index]))\n",
    "utils.plot_and_save(images, labels, './docs/images/25-random-images.jpg', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_images = {\n",
    "    'with bad lighting': [17894, 14044],\n",
    "    'good': [22842, 4220]\n",
    "}\n",
    "images = []\n",
    "labels = []\n",
    "for label, indices in example_images.items():\n",
    "    for i in indices:\n",
    "        images.append(training.X[i])\n",
    "        labels.append(utils.to_sign_label(training.y[i]))\n",
    "\n",
    "utils.plot_and_save(images, labels, 'docs/images/cherry-pick-good-bad-images.jpg', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process and augment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of enabled data augmenters for training data set\n",
    "TRAINING_DATA_AUGMENTERS = [\n",
    "    augmentation.GaussianBlurAugmenter(),\n",
    "    augmentation.AffineTransformAugmenter(),\n",
    "    augmentation.AffineTransformAugmenter(),\n",
    "    augmentation.AffineTransformAugmenter(),\n",
    "]\n",
    "d_train = augmentation.Augmenter.apply(training, TRAINING_DATA_AUGMENTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of enabled data pre-processors\n",
    "PRE_PROCESSORS = [\n",
    "    preprocessing.GrayScaleConverter(),\n",
    "    preprocessing.ZNormaliser(),\n",
    "]\n",
    "\n",
    "# Perform pre-processing on augmented training and validation data sets\n",
    "d_train = preprocessing.PreProcessor.apply(d_train, PRE_PROCESSORS)\n",
    "d_validation = preprocessing.PreProcessor.apply(validation, PRE_PROCESSORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pre-processing to two of the \"bad\" images to show the results\n",
    "BAD_IMAGE_INDEX = [17894, 14044]\n",
    "\n",
    "bad_x = np.zeros((2, 32, 32, 3))\n",
    "bad_y = np.zeros(2,)\n",
    "for i in range(len(BAD_IMAGE_INDEX)):\n",
    "    bad_x[i,:] = training.X[BAD_IMAGE_INDEX[i]]\n",
    "    bad_y[i] = training.y[BAD_IMAGE_INDEX[i]]\n",
    "bad_examples = loading.DataSet('bad_samples', bad_x, bad_y, len(bad_x))\n",
    "\n",
    "pre_processed = preprocessing.PreProcessor.apply(bad_examples, PRE_PROCESSORS)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for i in range(len(BAD_IMAGE_INDEX)):\n",
    "    images.append(training.X[BAD_IMAGE_INDEX[i]]);\n",
    "    labels.append('Original')\n",
    "\n",
    "    images.append(pre_processed.X[i].squeeze());\n",
    "    labels.append('Pre-processed')\n",
    "utils.plot_and_save(images, labels, './docs/images/bad-images-pre-processed.jpg', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Placeholders and setup computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "mode = tf.placeholder(tf.string, (None))\n",
    "\n",
    "training_operation, accuracy_operation, logits = lenet.setup_graph(x, y, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Hyper-parameters: %s', HYPER_PARAMETERS)\n",
    "\n",
    "HYPER_PARAMETERS['EPOCHS'] = 1\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = d_train.count\n",
    "\n",
    "    logger.info(\"Training...\")\n",
    "    for i in range(HYPER_PARAMETERS['EPOCHS']):\n",
    "        d_train = utils.shuffle(d_train)\n",
    "        for offset in range(0, num_examples, HYPER_PARAMETERS['BATCH_SIZE']):\n",
    "            end = offset + HYPER_PARAMETERS['BATCH_SIZE']\n",
    "            batch_x, batch_y = d_train.X[offset:end], d_train.y[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, mode: Mode.TRAINING.value})\n",
    "\n",
    "        training_accuracy = lenet.evaluation(d_train.X, d_train.y, x, y, mode, accuracy_operation)\n",
    "        validation_accuracy = lenet.evaluation(d_validation.X, d_validation.y, x, y, mode, accuracy_operation)\n",
    "        logger.info(\"EPOCH {} ...\".format(i + 1))\n",
    "        logger.info(\"Accuracy on training dataset = {:.3f}\".format(training_accuracy))\n",
    "        logger.info(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "\n",
    "    saver.save(sess, './data/model/lenet')\n",
    "    logger.info(\"Model saved\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "To give yourself more insight into how your model is working, download at least five pictures of German traffic signs from the web and use your model to predict the traffic sign type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM_INTERNET_IMAGE_PATHS = [\n",
    "    \"max-50.jpeg\",\n",
    "    \"max-70.jpeg\",\n",
    "    \"priority-road.jpg\",\n",
    "    \"right-of-way-at-next-intersection.jpg\",\n",
    "    \"stop.jpg\",\n",
    "    \"turn-right-ahead.jpg\"\n",
    "]\n",
    "FROM_INTERNET_LABELS = [2, 4, 12, 11, 14, 33]\n",
    "from_internet_images = [utils.read_image_for_lenet('./data/traffic-signs-from-internet/' + p) for p in FROM_INTERNET_IMAGE_PATHS]\n",
    "\n",
    "plt_labels = ['{}: {}'.format(l, utils.to_sign_label(l)) for l in FROM_INTERNET_LABELS]\n",
    "utils.plot_and_save(from_internet_images, plt_labels, './docs/images/images-from-internet-resized.jpg', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(training.y)\n",
    "indices = df.loc[df[0] == 33].reset_index()\n",
    "plt.imshow(training.X[indices['index'][10], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "\n",
    "d_x = np.stack(from_internet_images)\n",
    "d_y = np.array(FROM_INTERNET_LABELS)\n",
    "\n",
    "from_internet_dataset = loading.DataSet('From Internet', d_x, d_y, len(d_x))\n",
    "logger.info(utils.get_summary([from_internet_dataset]))\n",
    "from_internet_dataset = preprocessing.PreProcessor.apply(from_internet_dataset, PRE_PROCESSORS)\n",
    "\n",
    "\n",
    "softmax_logits = tf.nn.softmax(logits)\n",
    "top_k = tf.nn.top_k(softmax_logits, k=10)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver2 = tf.train.import_meta_graph('./data/model/lenet.meta')\n",
    "    saver2.restore(sess, \"./data/model/lenet\")\n",
    "    \n",
    "    # chkp.print_tensors_in_checkpoint_file(\"./data/model/lenet\", tensor_name='', all_tensors=True)\n",
    "\n",
    "    softmax_values = sess.run(softmax_logits, feed_dict={x: from_internet_dataset.X, mode: Mode.PREDICTING.value})\n",
    "    top_k_results = sess.run(top_k, feed_dict={x: from_internet_dataset.X, mode: Mode.PREDICTING.value})\n",
    "    validation_accuracy = lenet.evaluation(d_validation.X, d_validation.y, x, y, mode, accuracy_operation)\n",
    "    logger.info(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Expected: {}'.format(FROM_INTERNET_LABELS))\n",
    "print('Actual: {}'.format(top_k_results.indices[:, 0]))\n",
    "print('Probabilities: {}'.format(top_k_results.values[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(top_k_results.indices.shape[0]):\n",
    "    print('Actual: {}, {}'.format(FROM_INTERNET_LABELS[i], utils.to_sign_label(FROM_INTERNET_LABELS[i])))\n",
    "    for j in range(top_k_results.indices.shape[1]):\n",
    "        predicted_label = top_k_results.indices[i, j]\n",
    "        print(\"\\t[{}] {}: {}\".format(predicted_label, utils.to_sign_label(predicted_label), top_k_results.values[i, j]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
